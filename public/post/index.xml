<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on A minimal Hugo website</title>
    <link>https://www.storieswithdata.com/post/</link>
    <description>Recent content in Posts on A minimal Hugo website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 27 Sep 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://www.storieswithdata.com/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>On the independence issue</title>
      <link>https://www.storieswithdata.com/post/2017/09/27/on-the-independence-issue/</link>
      <pubDate>Wed, 27 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.storieswithdata.com/post/2017/09/27/on-the-independence-issue/</guid>
      <description>In this post, we will look at a list of different surveys from Wikipedia on Catalan Independence vote and plot using a box plot.
 Libraries We are going to use the following R packages:
# Load packages library(hrbrthemes) library(rvest) library(stringr) library(dplyr) library(lubridate) library(readr) library(hrbrthemes) # Aesthetic defaults for ggplot2 charts library(ggplot2) library(tidyverse)  Scraping With the rvest package we can scrape the content of the table.
 We first use the html_nodes() function to select the  nodes To parse the HTML table data we use html_table(), which would create a list We coerce the list to dataframe to be able to work with the data manipulaton  We are interested in the 7th table with title “On the independence issue”.</description>
    </item>
    
    <item>
      <title>Basic Text Mining in R</title>
      <link>https://www.storieswithdata.com/post/2017/09/25/basic-text-mining-in-r/</link>
      <pubDate>Mon, 25 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.storieswithdata.com/post/2017/09/25/basic-text-mining-in-r/</guid>
      <description>In this post, we will do some basic text mining of the speech in Madrid last May of Catalan president Carles Puigdemont.
 Libraries We are going to use the following R packages:
# Load packages library(stringr) library(dplyr) library(lubridate) library(readr) library(tm) # Process text documents in an effective manner. library(SnowballC) # Word stemming algorithm for collapsing words to a common root library(RColorBrewer) # Colors library(wordcloud) # Wordcloud library(hrbrthemes) # Aesthetic defaults for ggplot2 charts library(ggplot2)  Load texts We start by saving the text file (or files) in a folder titled: “texts” This will be the “corpus” (body) of texts you are mining.</description>
    </item>
    
    <item>
      <title>RSelenium &amp; Web Scraper Chrome to gather data</title>
      <link>https://www.storieswithdata.com/post/2017/09/21/using-rselenium-to-gather-data/</link>
      <pubDate>Thu, 21 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.storieswithdata.com/post/2017/09/21/using-rselenium-to-gather-data/</guid>
      <description>Intro  In this post, we scrape data and data wrangle to get a picture of type oj jobs offered in the expansion website.
  Libraries Overall, we are going to use the following R packages:
library(XML) # For web scraping library(rvest) # For web scraping library(tidyverse) # Data wrangling packages gather, spread... library(lubridate) # To work with dates library(hrbrthemes) # Aesthetic defaults for ggplot2 charts library(stringr) # For manipulating strings One way would be to make vector of all the urls you are interested in and then use sapply.</description>
    </item>
    
    <item>
      <title>Waffle charts and Spanish general elections</title>
      <link>https://www.storieswithdata.com/post/2017/09/21/using-waffle-charts-to-analyze-spanish-general-election-results-2016/</link>
      <pubDate>Thu, 21 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.storieswithdata.com/post/2017/09/21/using-waffle-charts-to-analyze-spanish-general-election-results-2016/</guid>
      <description>Intro  In this post we wil show how the waffle package can be used plotting 2016 Spanish general elections
 If you are interested in learning more about creating charts using the R Waffle package you can read more here:
 Make waffle (square pie) charts in R 1 Infographic-style charts using the R waffle package 2   Libraries We will first load the packages (you will have to install the packages if you haven’t done so before).</description>
    </item>
    
    <item>
      <title>A cool map</title>
      <link>https://www.storieswithdata.com/post/2017/09/20/a-cool-map/</link>
      <pubDate>Wed, 20 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.storieswithdata.com/post/2017/09/20/a-cool-map/</guid>
      <description>Intro  In this post we will be plotting population in Spain using Hex Bins in ggplot2.
  Libraries We will first load the packages.
library(stringr) # Manipulating strings library(tidyverse) # Data wrangling packages gather, spread... library(maps) # Spatial Visualization library(readr) # Read docs library(RColorBrewer) # Colors  Data Data comes from MAXMIND 1. We select ES.zip file (for Spain). We remove cities with no population and rename columns.</description>
    </item>
    
    <item>
      <title>Visualizing Spain’s demographics</title>
      <link>https://www.storieswithdata.com/post/2017/09/18/visualizing-spain-s-demographics/</link>
      <pubDate>Mon, 18 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.storieswithdata.com/post/2017/09/18/visualizing-spain-s-demographics/</guid>
      <description>Intro  Women have fewer children than ever in Spain since data exist. In fact, 2016 was the second consecutive year in which more people died than those who were born (negative vegetative balance). In this post our goal is to visualize this data.
  Libraries We will first load the packages.
library(hrbrthemes) # Aesthetic defaults for ggplot2 charts library(ggplot2) # Charts library(stringr) # Manipulating strings library(tidyverse) # Data wrangling packages gather, spread.</description>
    </item>
    
    <item>
      <title>Unemployment in Spain</title>
      <link>https://www.storieswithdata.com/post/2017/09/15/unemployment-in-spain/</link>
      <pubDate>Fri, 15 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.storieswithdata.com/post/2017/09/15/unemployment-in-spain/</guid>
      <description>Intro  In this post, we scrape data and data wrangle to get an overall picute of the job market.
 The data comes from the Instituto Nacional de Estadistica (INE) website 1.
 Libraries Overall, we are going to use the following R packages:
library(XML) # For web scraping library(rvest) # For web scraping library(dplyr) # For dataset manipulation library(hrbrthemes) # Aesthetic defaults for ggplot2 charts library(ggthemes) # Themes ggplot2 library(ggplot2) # Charts library(stringr) # Manipulating strings library(tidyverse) # Data wrangling packages gather, spread.</description>
    </item>
    
    <item>
      <title>Electric cars and metal prices</title>
      <link>https://www.storieswithdata.com/post/2017/09/14/electric-cars-and-metal-prices/</link>
      <pubDate>Thu, 14 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.storieswithdata.com/post/2017/09/14/electric-cars-and-metal-prices/</guid>
      <description>In this post we will analyze the evolution of metal prices on the back of the Electric car revolution
 Intro The electric vehicles industry is creating winners and losers within the world’s biggest metals markets.
In this regard, Cobalt is essential for lithium-ion batteries powering anything from Tesla Inc.’s cars to Apple Inc.’s iPhones and iPads 1.
 Libraries We first install and load the libraries.
library(ggplot2) # For amazing charts library(dplyr) # Data wrangling library(hrbrthemes) # Aesthetic defaults for ggplot2 charts library(Quandl) # Get financial data library(magrittr) # Pipes %&amp;gt;% library(tidyverse) # Data wrangling packages  Importing data We start by getting the prices for Cobalt, Nickel, Aluminium and Copper 2.</description>
    </item>
    
    <item>
      <title>BiciMad and Heatmaps</title>
      <link>https://www.storieswithdata.com/post/2017/09/13/bicimad-and-heatmaps/</link>
      <pubDate>Wed, 13 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.storieswithdata.com/post/2017/09/13/bicimad-and-heatmaps/</guid>
      <description>In this post we will analyze Madrid’s electric bike hire service, BiciMAD (in London Santander Cycles, in Paris Vélib, etc…). We will create calendar heatmaps and a growth chart using the publicly available data.
 Libraries We first install and load the libraries.
library(ggplot2) # For amazing charts library(tidyverse) # Data wrangling library(hrbrthemes) # Aesthetic defaults for ggplot2 charts library(readr) # Reading data from csv library(formattable) # Friendy data frame can be rendered as HTML table library(lubridate) # Makes it easier to work with dates and times  Importing data The data can be obtained from datosabiertos - the free and open data-sharing portal where anyone can access data relating to the Madrid 1.</description>
    </item>
    
    <item>
      <title>Joyplots with ggjoy and hrbrthmes</title>
      <link>https://www.storieswithdata.com/post/2017/09/12/joyplots-with-ggjoy-and-hrbrthmes/</link>
      <pubDate>Tue, 12 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.storieswithdata.com/post/2017/09/12/joyplots-with-ggjoy-and-hrbrthmes/</guid>
      <description>Haven’t you run into articles with some data that makes you think, how can visualize the data in a different and possibly better way?
 We will be use Joyplots for this post.
Joyplots are partially overlapping line plots that create the impression of a mountain range. They can be quite useful for visualizing changes in distributions over time or space 1.
The data that we will be looking at is 2016 temperatures in Lincoln, NE 23.</description>
    </item>
    
    <item>
      <title>Tennis winners - scraping and plotting</title>
      <link>https://www.storieswithdata.com/post/2017/09/11/tennis-winners-scrapig-and-plotting/</link>
      <pubDate>Mon, 11 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.storieswithdata.com/post/2017/09/11/tennis-winners-scrapig-and-plotting/</guid>
      <description>Intro  In this tutorial, we will be plotting tennis players Grand Slam Tournament wins.
 The data comes from the Tennis Grand Slam Tournaments results from the ESP website 1.
We will scrape the data and continue with the visualization thereafter.
 Libraries Overall, we are going to use the following R packages:
library(XML) # for web scraping library(rvest) # for web scraping library(dplyr) # for dataset manipulation library(knitr) # for nice dataset printing library(hrbrthemes) # Aesthetic defaults for ggplot2 charts library(ggthemes) # Themes ggplot2 library(ggplot2) # Charts library(stringr) # Manipulating strings  Scraping We will be scraping HTML Table with the XML package.</description>
    </item>
    
    <item>
      <title>JSON and Maps</title>
      <link>https://www.storieswithdata.com/post/2017/09/10/json-and-maps/</link>
      <pubDate>Sun, 10 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.storieswithdata.com/post/2017/09/10/json-and-maps/</guid>
      <description>Today we will extract information from a JSON document using the R package jsonlite and we will then plot lon/lat in a map using the R package leaflet.
The data that we will be looking at is crime in LA.
But first, we need to install and load libraries for this excercise.
library(jsonlite) library(tidyverse) library(stringr) library(tibble) library(leaflet) library(ggmap) library(readr) Now we can start grabbing the data from the json document which can be found here 1.</description>
    </item>
    
    <item>
      <title>A Quick Note on Building Websites</title>
      <link>https://www.storieswithdata.com/post/2017/09/09/a-quick-note-on-building-websites/</link>
      <pubDate>Sat, 09 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.storieswithdata.com/post/2017/09/09/a-quick-note-on-building-websites/</guid>
      <description>Note: Thanks to those who share their ideas and help others make things happen seamlessly.
 Finally! I now have a blog. All thanks to the R package Blogdown. With Blogdown you can creat a personal website.
 After reading many articles, watching videos and multiple failed attempts, I was able to get my picked Hugo theme up and running with R Studio and Blogdown.
There are many articles on the topic but the place I strongly recommend you visit is a youtube video by John Muschelli:</description>
    </item>
    
  </channel>
</rss>